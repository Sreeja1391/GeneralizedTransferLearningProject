args: {'dataset': 'CIFAR10', 'model_name': 'vgg16', 'model_weight': 'IMAGENET1K_V1', 'freeze_layers': 4, 'seed': 123, 'epochs': 30, 'use_gpu': True, 'train_valid_split': 0.1, 'filepath': '.pt', 'create_plot': True, 'batch_size': 128, 'lr': 0.0005, 'early_stop': True, 'early_stop_patience': 3, 'loss_delta': 0.0001}
Loading data...Files already downloaded and verified
train_size: 45000 valid_size: 5000
 0 features.0.weight            requires_grad = False  torch.Size([64, 3, 3, 3])
 1 features.0.bias              requires_grad = False  torch.Size([64])
 2 features.2.weight            requires_grad = False  torch.Size([64, 64, 3, 3])
 3 features.2.bias              requires_grad = False  torch.Size([64])
 4 features.5.weight            requires_grad = True  torch.Size([128, 64, 3, 3])
 5 features.5.bias              requires_grad = True  torch.Size([128])
 6 features.7.weight            requires_grad = True  torch.Size([128, 128, 3, 3])
 7 features.7.bias              requires_grad = True  torch.Size([128])
 8 features.10.weight           requires_grad = True  torch.Size([256, 128, 3, 3])
 9 features.10.bias             requires_grad = True  torch.Size([256])
10 features.12.weight           requires_grad = True  torch.Size([256, 256, 3, 3])
11 features.12.bias             requires_grad = True  torch.Size([256])
12 features.14.weight           requires_grad = True  torch.Size([256, 256, 3, 3])
13 features.14.bias             requires_grad = True  torch.Size([256])
14 features.17.weight           requires_grad = True  torch.Size([512, 256, 3, 3])
15 features.17.bias             requires_grad = True  torch.Size([512])
16 features.19.weight           requires_grad = True  torch.Size([512, 512, 3, 3])
17 features.19.bias             requires_grad = True  torch.Size([512])
18 features.21.weight           requires_grad = True  torch.Size([512, 512, 3, 3])
19 features.21.bias             requires_grad = True  torch.Size([512])
20 features.24.weight           requires_grad = True  torch.Size([512, 512, 3, 3])
21 features.24.bias             requires_grad = True  torch.Size([512])
22 features.26.weight           requires_grad = True  torch.Size([512, 512, 3, 3])
23 features.26.bias             requires_grad = True  torch.Size([512])
24 features.28.weight           requires_grad = True  torch.Size([512, 512, 3, 3])
25 features.28.bias             requires_grad = True  torch.Size([512])
26 classifier.0.weight          requires_grad = True  torch.Size([4096, 25088])
27 classifier.0.bias            requires_grad = True  torch.Size([4096])
28 classifier.3.weight          requires_grad = True  torch.Size([4096, 4096])
29 classifier.3.bias            requires_grad = True  torch.Size([4096])
30 classifier.6.weight          requires_grad = True  torch.Size([10, 4096])
31 classifier.6.bias            requires_grad = True  torch.Size([10])

epoch: 01/30 | batch 000/351 | loss: 2.6460
epoch: 01/30 | batch 100/351 | loss: 1.4002
epoch: 01/30 | batch 200/351 | loss: 0.9407
epoch: 01/30 | batch 300/351 | loss: 0.8571
epoch: 01/30 train acc: 0.7126 valid acc: 0.6978
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 0.46 min
epoch: 02/30 | batch 000/351 | loss: 0.7893
epoch: 02/30 | batch 100/351 | loss: 0.7580
epoch: 02/30 | batch 200/351 | loss: 0.7115
epoch: 02/30 | batch 300/351 | loss: 0.7985
epoch: 02/30 train acc: 0.8216 valid acc: 0.7882
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 0.90 min
epoch: 03/30 | batch 000/351 | loss: 0.3961
epoch: 03/30 | batch 100/351 | loss: 0.4996
epoch: 03/30 | batch 200/351 | loss: 0.5540
epoch: 03/30 | batch 300/351 | loss: 0.6433
epoch: 03/30 train acc: 0.8346 valid acc: 0.7868
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 1.35 min
epoch: 04/30 | batch 000/351 | loss: 0.3731
epoch: 04/30 | batch 100/351 | loss: 0.4362
epoch: 04/30 | batch 200/351 | loss: 0.5301
epoch: 04/30 | batch 300/351 | loss: 0.6352
epoch: 04/30 train acc: 0.8745 valid acc: 0.8142
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 1.81 min
epoch: 05/30 | batch 000/351 | loss: 0.3424
epoch: 05/30 | batch 100/351 | loss: 0.3816
epoch: 05/30 | batch 200/351 | loss: 0.3783
epoch: 05/30 | batch 300/351 | loss: 0.4206
epoch: 05/30 train acc: 0.8966 valid acc: 0.8134
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 2.26 min
epoch: 06/30 | batch 000/351 | loss: 0.3093
epoch: 06/30 | batch 100/351 | loss: 0.2098
epoch: 06/30 | batch 200/351 | loss: 0.3946
epoch: 06/30 | batch 300/351 | loss: 0.4246
epoch: 06/30 train acc: 0.9145 valid acc: 0.8326
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 2.70 min
epoch: 07/30 | batch 000/351 | loss: 0.2733
epoch: 07/30 | batch 100/351 | loss: 0.1733
epoch: 07/30 | batch 200/351 | loss: 0.2255
epoch: 07/30 | batch 300/351 | loss: 0.2802
epoch: 07/30 train acc: 0.9171 valid acc: 0.8298
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 3.16 min
epoch: 08/30 | batch 000/351 | loss: 0.2933
epoch: 08/30 | batch 100/351 | loss: 0.2664
epoch: 08/30 | batch 200/351 | loss: 0.4846
epoch: 08/30 | batch 300/351 | loss: 0.3829
epoch: 08/30 train acc: 0.9263 valid acc: 0.8280
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 3.61 min
epoch: 09/30 | batch 000/351 | loss: 0.1301
epoch: 09/30 | batch 100/351 | loss: 0.4121
epoch: 09/30 | batch 200/351 | loss: 0.1472
epoch: 09/30 | batch 300/351 | loss: 0.2129
epoch: 09/30 train acc: 0.9326 valid acc: 0.8212
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 4.06 min
epoch: 10/30 | batch 000/351 | loss: 0.2869
epoch: 10/30 | batch 100/351 | loss: 0.1938
epoch: 10/30 | batch 200/351 | loss: 0.3369
epoch: 10/30 | batch 300/351 | loss: 0.2882
epoch: 10/30 train acc: 0.9425 valid acc: 0.8398
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 4.50 min
epoch: 11/30 | batch 000/351 | loss: 0.4860
epoch: 11/30 | batch 100/351 | loss: 0.0929
epoch: 11/30 | batch 200/351 | loss: 0.3332
epoch: 11/30 | batch 300/351 | loss: 0.2527
epoch: 11/30 train acc: 0.9408 valid acc: 0.8294
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Saving model...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001.pt
Saving loss...to CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Total training #epoch: 10
Total training time: 6.48 min
Loading data...Files already downloaded and verified
test_size: 10000
Loading model...from CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001.pt
test acc: 0.8466
Loading loss...from CIFAR10-vgg16-freeze4-batch128-epoch30-lr0.0005-earlystop3-0.0001.pt
