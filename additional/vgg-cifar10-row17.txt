args: {'dataset': 'CIFAR10', 'model_name': 'vgg16', 'model_weight': 'IMAGENET1K_V1', 'freeze_layers': 0, 'seed': 123, 'epochs': 30, 'use_gpu': True, 'train_valid_split': 0.1, 'filepath': '.pt', 'create_plot': True, 'batch_size': 128, 'lr': 0.0005, 'early_stop': True, 'early_stop_patience': 3, 'loss_delta': 0.0001}
Loading data...Files already downloaded and verified
train_size: 45000 valid_size: 5000
 0 features.0.weight            requires_grad = True  torch.Size([64, 3, 3, 3])
 1 features.0.bias              requires_grad = True  torch.Size([64])
 2 features.2.weight            requires_grad = True  torch.Size([64, 64, 3, 3])
 3 features.2.bias              requires_grad = True  torch.Size([64])
 4 features.5.weight            requires_grad = True  torch.Size([128, 64, 3, 3])
 5 features.5.bias              requires_grad = True  torch.Size([128])
 6 features.7.weight            requires_grad = True  torch.Size([128, 128, 3, 3])
 7 features.7.bias              requires_grad = True  torch.Size([128])
 8 features.10.weight           requires_grad = True  torch.Size([256, 128, 3, 3])
 9 features.10.bias             requires_grad = True  torch.Size([256])
10 features.12.weight           requires_grad = True  torch.Size([256, 256, 3, 3])
11 features.12.bias             requires_grad = True  torch.Size([256])
12 features.14.weight           requires_grad = True  torch.Size([256, 256, 3, 3])
13 features.14.bias             requires_grad = True  torch.Size([256])
14 features.17.weight           requires_grad = True  torch.Size([512, 256, 3, 3])
15 features.17.bias             requires_grad = True  torch.Size([512])
16 features.19.weight           requires_grad = True  torch.Size([512, 512, 3, 3])
17 features.19.bias             requires_grad = True  torch.Size([512])
18 features.21.weight           requires_grad = True  torch.Size([512, 512, 3, 3])
19 features.21.bias             requires_grad = True  torch.Size([512])
20 features.24.weight           requires_grad = True  torch.Size([512, 512, 3, 3])
21 features.24.bias             requires_grad = True  torch.Size([512])
22 features.26.weight           requires_grad = True  torch.Size([512, 512, 3, 3])
23 features.26.bias             requires_grad = True  torch.Size([512])
24 features.28.weight           requires_grad = True  torch.Size([512, 512, 3, 3])
25 features.28.bias             requires_grad = True  torch.Size([512])
26 classifier.0.weight          requires_grad = True  torch.Size([4096, 25088])
27 classifier.0.bias            requires_grad = True  torch.Size([4096])
28 classifier.3.weight          requires_grad = True  torch.Size([4096, 4096])
29 classifier.3.bias            requires_grad = True  torch.Size([4096])
30 classifier.6.weight          requires_grad = True  torch.Size([10, 4096])
31 classifier.6.bias            requires_grad = True  torch.Size([10])

epoch: 01/30 | batch 000/351 | loss: 2.6460
epoch: 01/30 | batch 100/351 | loss: 0.9619
epoch: 01/30 | batch 200/351 | loss: 0.8051
epoch: 01/30 | batch 300/351 | loss: 0.9108
epoch: 01/30 train acc: 0.7699 valid acc: 0.7538
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 0.48 min
epoch: 02/30 | batch 000/351 | loss: 0.9383
epoch: 02/30 | batch 100/351 | loss: 0.6601
epoch: 02/30 | batch 200/351 | loss: 0.6497
epoch: 02/30 | batch 300/351 | loss: 0.7895
epoch: 02/30 train acc: 0.8204 valid acc: 0.7780
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 0.94 min
epoch: 03/30 | batch 000/351 | loss: 0.3802
epoch: 03/30 | batch 100/351 | loss: 0.5412
epoch: 03/30 | batch 200/351 | loss: 0.4834
epoch: 03/30 | batch 300/351 | loss: 0.6327
epoch: 03/30 train acc: 0.8452 valid acc: 0.7838
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 1.41 min
epoch: 04/30 | batch 000/351 | loss: 0.4660
epoch: 04/30 | batch 100/351 | loss: 0.3606
epoch: 04/30 | batch 200/351 | loss: 0.5424
epoch: 04/30 | batch 300/351 | loss: 0.6063
epoch: 04/30 train acc: 0.8578 valid acc: 0.8002
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 1.88 min
epoch: 05/30 | batch 000/351 | loss: 0.4229
epoch: 05/30 | batch 100/351 | loss: 0.4877
epoch: 05/30 | batch 200/351 | loss: 0.3691
epoch: 05/30 | batch 300/351 | loss: 0.3606
epoch: 05/30 train acc: 0.9096 valid acc: 0.8318
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 2.34 min
epoch: 06/30 | batch 000/351 | loss: 0.2729
epoch: 06/30 | batch 100/351 | loss: 0.1765
epoch: 06/30 | batch 200/351 | loss: 0.3188
epoch: 06/30 | batch 300/351 | loss: 0.4475
epoch: 06/30 train acc: 0.8902 valid acc: 0.8116
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 2.81 min
epoch: 07/30 | batch 000/351 | loss: 0.3484
epoch: 07/30 | batch 100/351 | loss: 0.2865
epoch: 07/30 | batch 200/351 | loss: 0.3977
epoch: 07/30 | batch 300/351 | loss: 0.2996
epoch: 07/30 train acc: 0.9265 valid acc: 0.8432
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 3.27 min
epoch: 08/30 | batch 000/351 | loss: 0.2978
epoch: 08/30 | batch 100/351 | loss: 0.3536
epoch: 08/30 | batch 200/351 | loss: 0.3576
epoch: 08/30 | batch 300/351 | loss: 0.3788
epoch: 08/30 train acc: 0.9334 valid acc: 0.8380
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 3.73 min
epoch: 09/30 | batch 000/351 | loss: 0.1666
epoch: 09/30 | batch 100/351 | loss: 0.4036
epoch: 09/30 | batch 200/351 | loss: 0.2633
epoch: 09/30 | batch 300/351 | loss: 0.2406
epoch: 09/30 train acc: 0.9410 valid acc: 0.8412
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 4.19 min
epoch: 10/30 | batch 000/351 | loss: 0.2164
epoch: 10/30 | batch 100/351 | loss: 0.2091
epoch: 10/30 | batch 200/351 | loss: 0.3582
epoch: 10/30 | batch 300/351 | loss: 0.2419
epoch: 10/30 train acc: 0.9346 valid acc: 0.8298
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Time elapsed: 4.65 min
epoch: 11/30 | batch 000/351 | loss: 0.2961
epoch: 11/30 | batch 100/351 | loss: 0.2141
epoch: 11/30 | batch 200/351 | loss: 0.3050
epoch: 11/30 | batch 300/351 | loss: 0.3432
epoch: 11/30 train acc: 0.9386 valid acc: 0.8328
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Saving model...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001.pt
Saving loss...to CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001-loss.pt
Total training #epoch: 10
Total training time: 6.46 min
Loading data...Files already downloaded and verified
test_size: 10000
Loading model...from CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001.pt
test acc: 0.8536
Loading loss...from CIFAR10-vgg16-freeze0-batch128-epoch30-lr0.0005-earlystop3-0.0001.pt
