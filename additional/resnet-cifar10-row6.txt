args: {'dataset': 'CIFAR10', 'model_name': 'resnet18', 'model_weight': 'IMAGENET1K_V1', 'freeze_layers': 3, 'seed': 123, 'epochs': 30, 'use_gpu': True, 'train_valid_split': 0.1, 'filepath': '.pt', 'create_plot': True, 'batch_size': 64, 'lr': 0.01, 'early_stop': True, 'early_stop_patience': 3, 'loss_delta': 0.0001}
Loading data...Files already downloaded and verified
train_size: 45000 valid_size: 5000
 0 conv1.weight                 requires_grad = False  torch.Size([64, 3, 7, 7])
 1 bn1.weight                   requires_grad = False  torch.Size([64])
 2 bn1.bias                     requires_grad = False  torch.Size([64])
 3 layer1.0.conv1.weight        requires_grad = True  torch.Size([64, 64, 3, 3])
 4 layer1.0.bn1.weight          requires_grad = True  torch.Size([64])
 5 layer1.0.bn1.bias            requires_grad = True  torch.Size([64])
 6 layer1.0.conv2.weight        requires_grad = True  torch.Size([64, 64, 3, 3])
 7 layer1.0.bn2.weight          requires_grad = True  torch.Size([64])
 8 layer1.0.bn2.bias            requires_grad = True  torch.Size([64])
 9 layer1.1.conv1.weight        requires_grad = True  torch.Size([64, 64, 3, 3])
10 layer1.1.bn1.weight          requires_grad = True  torch.Size([64])
11 layer1.1.bn1.bias            requires_grad = True  torch.Size([64])
12 layer1.1.conv2.weight        requires_grad = True  torch.Size([64, 64, 3, 3])
13 layer1.1.bn2.weight          requires_grad = True  torch.Size([64])
14 layer1.1.bn2.bias            requires_grad = True  torch.Size([64])
15 layer2.0.conv1.weight        requires_grad = True  torch.Size([128, 64, 3, 3])
16 layer2.0.bn1.weight          requires_grad = True  torch.Size([128])
17 layer2.0.bn1.bias            requires_grad = True  torch.Size([128])
18 layer2.0.conv2.weight        requires_grad = True  torch.Size([128, 128, 3, 3])
19 layer2.0.bn2.weight          requires_grad = True  torch.Size([128])
20 layer2.0.bn2.bias            requires_grad = True  torch.Size([128])
21 layer2.0.downsample.0.weight requires_grad = True  torch.Size([128, 64, 1, 1])
22 layer2.0.downsample.1.weight requires_grad = True  torch.Size([128])
23 layer2.0.downsample.1.bias   requires_grad = True  torch.Size([128])
24 layer2.1.conv1.weight        requires_grad = True  torch.Size([128, 128, 3, 3])
25 layer2.1.bn1.weight          requires_grad = True  torch.Size([128])
26 layer2.1.bn1.bias            requires_grad = True  torch.Size([128])
27 layer2.1.conv2.weight        requires_grad = True  torch.Size([128, 128, 3, 3])
28 layer2.1.bn2.weight          requires_grad = True  torch.Size([128])
29 layer2.1.bn2.bias            requires_grad = True  torch.Size([128])
30 layer3.0.conv1.weight        requires_grad = True  torch.Size([256, 128, 3, 3])
31 layer3.0.bn1.weight          requires_grad = True  torch.Size([256])
32 layer3.0.bn1.bias            requires_grad = True  torch.Size([256])
33 layer3.0.conv2.weight        requires_grad = True  torch.Size([256, 256, 3, 3])
34 layer3.0.bn2.weight          requires_grad = True  torch.Size([256])
35 layer3.0.bn2.bias            requires_grad = True  torch.Size([256])
36 layer3.0.downsample.0.weight requires_grad = True  torch.Size([256, 128, 1, 1])
37 layer3.0.downsample.1.weight requires_grad = True  torch.Size([256])
38 layer3.0.downsample.1.bias   requires_grad = True  torch.Size([256])
39 layer3.1.conv1.weight        requires_grad = True  torch.Size([256, 256, 3, 3])
40 layer3.1.bn1.weight          requires_grad = True  torch.Size([256])
41 layer3.1.bn1.bias            requires_grad = True  torch.Size([256])
42 layer3.1.conv2.weight        requires_grad = True  torch.Size([256, 256, 3, 3])
43 layer3.1.bn2.weight          requires_grad = True  torch.Size([256])
44 layer3.1.bn2.bias            requires_grad = True  torch.Size([256])
45 layer4.0.conv1.weight        requires_grad = True  torch.Size([512, 256, 3, 3])
46 layer4.0.bn1.weight          requires_grad = True  torch.Size([512])
47 layer4.0.bn1.bias            requires_grad = True  torch.Size([512])
48 layer4.0.conv2.weight        requires_grad = True  torch.Size([512, 512, 3, 3])
49 layer4.0.bn2.weight          requires_grad = True  torch.Size([512])
50 layer4.0.bn2.bias            requires_grad = True  torch.Size([512])
51 layer4.0.downsample.0.weight requires_grad = True  torch.Size([512, 256, 1, 1])
52 layer4.0.downsample.1.weight requires_grad = True  torch.Size([512])
53 layer4.0.downsample.1.bias   requires_grad = True  torch.Size([512])
54 layer4.1.conv1.weight        requires_grad = True  torch.Size([512, 512, 3, 3])
55 layer4.1.bn1.weight          requires_grad = True  torch.Size([512])
56 layer4.1.bn1.bias            requires_grad = True  torch.Size([512])
57 layer4.1.conv2.weight        requires_grad = True  torch.Size([512, 512, 3, 3])
58 layer4.1.bn2.weight          requires_grad = True  torch.Size([512])
59 layer4.1.bn2.bias            requires_grad = True  torch.Size([512])
60 fc.weight                    requires_grad = True  torch.Size([10, 512])
61 fc.bias                      requires_grad = True  torch.Size([10])

epoch: 01/30 | batch 000/703 | loss: 2.6352
epoch: 01/30 | batch 100/703 | loss: 3.2536
epoch: 01/30 | batch 200/703 | loss: 2.0716
epoch: 01/30 | batch 300/703 | loss: 2.0849
epoch: 01/30 | batch 400/703 | loss: 2.0165
epoch: 01/30 | batch 500/703 | loss: 1.7703
epoch: 01/30 | batch 600/703 | loss: 1.5311
epoch: 01/30 | batch 700/703 | loss: 1.6802
epoch: 01/30 train acc: 0.3932 valid acc: 0.3906
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 0.46 min
epoch: 02/30 | batch 000/703 | loss: 1.9202
epoch: 02/30 | batch 100/703 | loss: 1.7495
epoch: 02/30 | batch 200/703 | loss: 1.5913
epoch: 02/30 | batch 300/703 | loss: 1.7146
epoch: 02/30 | batch 400/703 | loss: 1.3954
epoch: 02/30 | batch 500/703 | loss: 1.3035
epoch: 02/30 | batch 600/703 | loss: 1.2694
epoch: 02/30 | batch 700/703 | loss: 1.0908
epoch: 02/30 train acc: 0.5116 valid acc: 0.4946
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 0.92 min
epoch: 03/30 | batch 000/703 | loss: 1.2264
epoch: 03/30 | batch 100/703 | loss: 1.2861
epoch: 03/30 | batch 200/703 | loss: 1.2820
epoch: 03/30 | batch 300/703 | loss: 1.1273
epoch: 03/30 | batch 400/703 | loss: 1.2076
epoch: 03/30 | batch 500/703 | loss: 1.1344
epoch: 03/30 | batch 600/703 | loss: 1.1707
epoch: 03/30 | batch 700/703 | loss: 1.1869
epoch: 03/30 train acc: 0.5970 valid acc: 0.5764
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 1.31 min
epoch: 04/30 | batch 000/703 | loss: 1.0482
epoch: 04/30 | batch 100/703 | loss: 1.1247
epoch: 04/30 | batch 200/703 | loss: 1.1820
epoch: 04/30 | batch 300/703 | loss: 1.1206
epoch: 04/30 | batch 400/703 | loss: 1.1075
epoch: 04/30 | batch 500/703 | loss: 1.0761
epoch: 04/30 | batch 600/703 | loss: 1.3052
epoch: 04/30 | batch 700/703 | loss: 1.0645
epoch: 04/30 train acc: 0.6085 valid acc: 0.5894
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 1.70 min
epoch: 05/30 | batch 000/703 | loss: 1.1133
epoch: 05/30 | batch 100/703 | loss: 1.0093
epoch: 05/30 | batch 200/703 | loss: 0.8916
epoch: 05/30 | batch 300/703 | loss: 0.8497
epoch: 05/30 | batch 400/703 | loss: 1.2627
epoch: 05/30 | batch 500/703 | loss: 1.0242
epoch: 05/30 | batch 600/703 | loss: 0.7547
epoch: 05/30 | batch 700/703 | loss: 1.0667
epoch: 05/30 train acc: 0.5537 valid acc: 0.5312
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 2.11 min
epoch: 06/30 | batch 000/703 | loss: 1.0814
epoch: 06/30 | batch 100/703 | loss: 1.0432
epoch: 06/30 | batch 200/703 | loss: 1.0169
epoch: 06/30 | batch 300/703 | loss: 0.8815
epoch: 06/30 | batch 400/703 | loss: 1.1621
epoch: 06/30 | batch 500/703 | loss: 1.1402
epoch: 06/30 | batch 600/703 | loss: 0.9616
epoch: 06/30 | batch 700/703 | loss: 0.7203
epoch: 06/30 train acc: 0.6775 valid acc: 0.6420
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 2.50 min
epoch: 07/30 | batch 000/703 | loss: 0.7948
epoch: 07/30 | batch 100/703 | loss: 0.8287
epoch: 07/30 | batch 200/703 | loss: 1.0185
epoch: 07/30 | batch 300/703 | loss: 0.7624
epoch: 07/30 | batch 400/703 | loss: 0.6808
epoch: 07/30 | batch 500/703 | loss: 0.7392
epoch: 07/30 | batch 600/703 | loss: 0.6431
epoch: 07/30 | batch 700/703 | loss: 0.7391
epoch: 07/30 train acc: 0.7083 valid acc: 0.6650
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 2.89 min
epoch: 08/30 | batch 000/703 | loss: 0.7849
epoch: 08/30 | batch 100/703 | loss: 0.8850
epoch: 08/30 | batch 200/703 | loss: 0.7761
epoch: 08/30 | batch 300/703 | loss: 0.8412
epoch: 08/30 | batch 400/703 | loss: 0.5124
epoch: 08/30 | batch 500/703 | loss: 0.6818
epoch: 08/30 | batch 600/703 | loss: 0.7637
epoch: 08/30 | batch 700/703 | loss: 0.7334
epoch: 08/30 train acc: 0.7325 valid acc: 0.6808
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 3.30 min
epoch: 09/30 | batch 000/703 | loss: 0.7549
epoch: 09/30 | batch 100/703 | loss: 0.8022
epoch: 09/30 | batch 200/703 | loss: 0.6921
epoch: 09/30 | batch 300/703 | loss: 1.1878
epoch: 09/30 | batch 400/703 | loss: 0.5798
epoch: 09/30 | batch 500/703 | loss: 0.7633
epoch: 09/30 | batch 600/703 | loss: 0.8349
epoch: 09/30 | batch 700/703 | loss: 0.8605
epoch: 09/30 train acc: 0.7489 valid acc: 0.6932
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 3.69 min
epoch: 10/30 | batch 000/703 | loss: 0.7345
epoch: 10/30 | batch 100/703 | loss: 0.7283
epoch: 10/30 | batch 200/703 | loss: 0.5450
epoch: 10/30 | batch 300/703 | loss: 0.6391
epoch: 10/30 | batch 400/703 | loss: 0.5164
epoch: 10/30 | batch 500/703 | loss: 0.6705
epoch: 10/30 | batch 600/703 | loss: 0.7437
epoch: 10/30 | batch 700/703 | loss: 0.6630
epoch: 10/30 train acc: 0.7530 valid acc: 0.6896
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 4.12 min
epoch: 11/30 | batch 000/703 | loss: 0.5846
epoch: 11/30 | batch 100/703 | loss: 0.6777
epoch: 11/30 | batch 200/703 | loss: 0.5446
epoch: 11/30 | batch 300/703 | loss: 0.6014
epoch: 11/30 | batch 400/703 | loss: 0.8019
epoch: 11/30 | batch 500/703 | loss: 0.7746
epoch: 11/30 | batch 600/703 | loss: 0.6740
epoch: 11/30 | batch 700/703 | loss: 0.6866
epoch: 11/30 train acc: 0.7854 valid acc: 0.7056
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 4.50 min
epoch: 12/30 | batch 000/703 | loss: 0.7500
epoch: 12/30 | batch 100/703 | loss: 0.8324
epoch: 12/30 | batch 200/703 | loss: 0.6129
epoch: 12/30 | batch 300/703 | loss: 0.7387
epoch: 12/30 | batch 400/703 | loss: 0.3725
epoch: 12/30 | batch 500/703 | loss: 0.6811
epoch: 12/30 | batch 600/703 | loss: 0.6680
epoch: 12/30 | batch 700/703 | loss: 0.6574
epoch: 12/30 train acc: 0.8116 valid acc: 0.7316
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 4.94 min
epoch: 13/30 | batch 000/703 | loss: 0.5672
epoch: 13/30 | batch 100/703 | loss: 0.6614
epoch: 13/30 | batch 200/703 | loss: 0.5297
epoch: 13/30 | batch 300/703 | loss: 0.4417
epoch: 13/30 | batch 400/703 | loss: 0.7086
epoch: 13/30 | batch 500/703 | loss: 0.5773
epoch: 13/30 | batch 600/703 | loss: 0.6866
epoch: 13/30 | batch 700/703 | loss: 0.6627
epoch: 13/30 train acc: 0.8118 valid acc: 0.7250
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 5.33 min
epoch: 14/30 | batch 000/703 | loss: 0.3707
epoch: 14/30 | batch 100/703 | loss: 0.5339
epoch: 14/30 | batch 200/703 | loss: 0.6058
epoch: 14/30 | batch 300/703 | loss: 0.5289
epoch: 14/30 | batch 400/703 | loss: 0.7804
epoch: 14/30 | batch 500/703 | loss: 0.4912
epoch: 14/30 | batch 600/703 | loss: 0.6251
epoch: 14/30 | batch 700/703 | loss: 0.5387
epoch: 14/30 train acc: 0.8213 valid acc: 0.7242
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 5.74 min
epoch: 15/30 | batch 000/703 | loss: 0.5885
epoch: 15/30 | batch 100/703 | loss: 0.5202
epoch: 15/30 | batch 200/703 | loss: 0.5372
epoch: 15/30 | batch 300/703 | loss: 0.5065
epoch: 15/30 | batch 400/703 | loss: 0.7050
epoch: 15/30 | batch 500/703 | loss: 0.8123
epoch: 15/30 | batch 600/703 | loss: 0.7415
epoch: 15/30 | batch 700/703 | loss: 0.6078
epoch: 15/30 train acc: 0.8112 valid acc: 0.7106
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Time elapsed: 6.11 min
epoch: 16/30 | batch 000/703 | loss: 0.4224
epoch: 16/30 | batch 100/703 | loss: 0.4935
epoch: 16/30 | batch 200/703 | loss: 0.3557
epoch: 16/30 | batch 300/703 | loss: 0.4284
epoch: 16/30 | batch 400/703 | loss: 0.4751
epoch: 16/30 | batch 500/703 | loss: 0.5725
epoch: 16/30 | batch 600/703 | loss: 0.6490
epoch: 16/30 | batch 700/703 | loss: 0.5163
epoch: 16/30 train acc: 0.8395 valid acc: 0.7268
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Saving model...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001.pt
Saving loss...to CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001-loss.pt
Total training #epoch: 15
Total training time: 6.62 min
Loading data...Files already downloaded and verified
test_size: 10000
Loading model...from CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001.pt
test acc: 0.7638
Loading loss...from CIFAR10-resnet18-freeze3-batch64-epoch30-lr0.01-earlystop3-0.0001.pt
